{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tqdm\\std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8, 6\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from torch.nn import init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "import glob\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "tqdm.pandas(desc='Progress')\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from market import *\n",
    "from market_ml import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionColumnarDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, cats, y):\n",
    "        self.dfcats = df[cats]\n",
    "        self.dfconts = df.drop(cats, axis=1)\n",
    "        \n",
    "        self.cats = np.stack([c.values for n, c in self.dfcats.items()], axis=1).astype(np.int64)\n",
    "        self.conts = np.stack([c.values for n, c in self.dfconts.items()], axis=1).astype(np.float32)\n",
    "        self.y = y.values.astype(np.float32)\n",
    "        \n",
    "    def __len__(self): return len(self.y)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.cats[idx], self.conts[idx], self.y[idx]]\n",
    "    \n",
    "def apply_dl(X, y, categorical):\n",
    "    ds = RegressionColumnarDataset(X, categorical, y)\n",
    "    params = {'batch_size': 128,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "    return torch.utils.data.DataLoader(ds, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 164/219 [01:05<00:51,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data from csv_files\\company_stats_2020-04-09.csv failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 188/219 [01:27<00:30,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data from csv_files\\company_stats_2020-05-17.csv failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:59<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master dataframe columns:  Index(['index', 'Ticker', 'Name', 'Sector', 'Industry', 'IPO Year', 'Price',\n",
      "       'Market Cap', 'Trailing P/E', 'Forward P/E', 'PEG Ratio(5yr Expected)',\n",
      "       'Price/Sales(ttm)', 'Price/Book', 'Enterprise Value/Revenue',\n",
      "       'Enterprise Value/EBITDA', 'Profit Margin', 'Operating Margin(TTM)',\n",
      "       'Return on Assets(TTM)', 'Return on Equity(TTM)', 'Revenue(TTM)',\n",
      "       'Revenue Per Share(TTM)', 'Quarterly Revenue Growth(YOY)',\n",
      "       'Gross Profit(TTM)', 'EBITDA', 'Diluted EPS(TTM)',\n",
      "       'Quarterly Earnings Growth(YOY)', 'Total Cash', 'Total Cash Per Share',\n",
      "       'Total Debt', 'Total Debt/Equity', 'Current Ratio',\n",
      "       'Book Value Per Share', 'Operating Cash Flow(TTM)',\n",
      "       'Levered Free Cash Flow(TTM)', 'Beta(3Y Monthly)', 'Shares Outstanding',\n",
      "       'Forward Annual Dividend Rate', 'Forward Annual Dividend Yield',\n",
      "       'Trailing Annual Dividend Rate', 'Trailing Annual Dividend Yield',\n",
      "       '5 Year Average Dividend Yield', 'Payout Ratio', 'EPS Beat Ratio',\n",
      "       'Market Cap (intraday)', 'PEG Ratio (5 yr expected)', 'Price/Sales',\n",
      "       'Operating Margin', 'Return on Assets', 'Return on Equity', 'Revenue',\n",
      "       'Revenue Per Share', 'Quarterly Revenue Growth', 'Gross Profit',\n",
      "       'Diluted EPS', 'Quarterly Earnings Growth', 'Operating Cash Flow',\n",
      "       'Levered Free Cash Flow', 'Beta (3Y Monthly)',\n",
      "       'Net Income Avi to Common', 'Enterprise Value'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def load_csv_data():\n",
    "    csv_filenames = glob.glob(\"csv_files/company_stats_*.csv\")\n",
    "    financial_data = pd.DataFrame()\n",
    "    for csv_name in tqdm(csv_filenames):\n",
    "        # Remove rows with nan values for industry and sector\n",
    "        try:\n",
    "            daily_data = pd.read_csv(csv_name, encoding='cp1252')\n",
    "            daily_data = daily_data[pd.notnull(daily_data['Industry'])] \n",
    "            daily_data = daily_data[pd.notnull(daily_data['Sector'])]\n",
    "            financial_data = financial_data.append(daily_data, sort=False)\n",
    "        except:\n",
    "            print('Importing data from', csv_name, 'failed.')\n",
    "\n",
    "    financial_data = financial_data.reset_index()\n",
    "    print('Master dataframe columns: ', financial_data.columns)\n",
    "\n",
    "    # Convert sector and industry to categoricals\n",
    "    financial_data['Industry'] = financial_data['Industry'].astype('category')\n",
    "    financial_data['Sector'] = financial_data['Sector'].astype('category')\n",
    "\n",
    "    to_remove = ['Ticker', 'Name', 'Price', 'IPO Year']\n",
    "    categorical = ['Sector', 'Industry']\n",
    "\n",
    "    # Convert categorical variables to integers to feed in the model\n",
    "    financial_data[categorical] = financial_data[categorical].apply(lambda x: x.cat.codes)\n",
    "    feature_cols = [x for x in financial_data.columns if x not in to_remove]\n",
    "    financial_data = financial_data.fillna(0)\n",
    "    X = financial_data[feature_cols]\n",
    "    Y = financial_data['Price']\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "X, Y = load_csv_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=123)\n",
    "    \n",
    "# Covert to dataloaders\n",
    "traindl = apply_dl(X_train, y_train, categorical)\n",
    "valdl = apply_dl(X_test, y_test, categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [10:45<00:00, 14.03s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Diluted EPS</th>\n",
       "      <th>Revenue Per Share</th>\n",
       "      <th>Trailing P/E</th>\n",
       "      <th>Forward Annual Dividend Rate</th>\n",
       "      <th>Price/Book</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Enterprise Value/EBITDA</th>\n",
       "      <th>Return on Equity</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>Operating Cash Flow</th>\n",
       "      <th>Gross Profit</th>\n",
       "      <th>Quarterly Earnings Growth</th>\n",
       "      <th>PEG Ratio</th>\n",
       "      <th>Total Cash</th>\n",
       "      <th>Total Debt/Equity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Total Debt</th>\n",
       "      <th>Enterprise Value</th>\n",
       "      <th>Return on Assets</th>\n",
       "      <th>Price</th>\n",
       "      <th>EPS Beat Ratio</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Enterprise Value/Revenue</th>\n",
       "      <th>Operating Margin</th>\n",
       "      <th>IPO Year</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Total Cash Per Share</th>\n",
       "      <th>Profit Margin</th>\n",
       "      <th>Price/Sales</th>\n",
       "      <th>Levered Free Cash Flow</th>\n",
       "      <th>Forward Annual Dividend Yield</th>\n",
       "      <th>5 Year Average Dividend Yield</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Net Income</th>\n",
       "      <th>Payout Ratio</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Dividend Yield</th>\n",
       "      <th>Shares Outstanding</th>\n",
       "      <th>Dividend Rate</th>\n",
       "      <th>index</th>\n",
       "      <th>Book Value Per Share</th>\n",
       "      <th>Quarterly Revenue Growth</th>\n",
       "      <th>Forward P/E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>PIH</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.185</td>\n",
       "      <td>9.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>327</td>\n",
       "      <td>0.76</td>\n",
       "      <td>118.12</td>\n",
       "      <td>0.97</td>\n",
       "      <td>118.12</td>\n",
       "      <td>8630000.0</td>\n",
       "      <td>15490000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2310000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1347 Property Insurance Holdings, Inc.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4.8348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2.922200e+07</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-9.79</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-80710000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6010000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>TURN</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>156</td>\n",
       "      <td>282.44</td>\n",
       "      <td>-24.40</td>\n",
       "      <td>-3.19</td>\n",
       "      <td>-24.40</td>\n",
       "      <td>-5850000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-39.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5870000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180 Degree Capital Corp.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.44</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>2.1294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>282.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.654100e+07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>314.30</td>\n",
       "      <td>2120000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31120000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FLWS</td>\n",
       "      <td>10</td>\n",
       "      <td>0.520</td>\n",
       "      <td>19.41</td>\n",
       "      <td>28.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.76</td>\n",
       "      <td>303</td>\n",
       "      <td>0.72</td>\n",
       "      <td>11.96</td>\n",
       "      <td>10.57</td>\n",
       "      <td>11.96</td>\n",
       "      <td>78100000.0</td>\n",
       "      <td>526120000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.34</td>\n",
       "      <td>172920000.0</td>\n",
       "      <td>28.3</td>\n",
       "      <td>1-800 FLOWERS.COM, Inc.</td>\n",
       "      <td>96970000.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>4.79</td>\n",
       "      <td>15.4100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.72</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>9.542680e+08</td>\n",
       "      <td>2.69</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>34370000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35770000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FCCY</td>\n",
       "      <td>12</td>\n",
       "      <td>1.620</td>\n",
       "      <td>6.13</td>\n",
       "      <td>10.77</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.11</td>\n",
       "      <td>379</td>\n",
       "      <td>4.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14330000.0</td>\n",
       "      <td>50220000.0</td>\n",
       "      <td>80.1</td>\n",
       "      <td>1.32</td>\n",
       "      <td>30110000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1st Constitution Bancorp (NJ)</td>\n",
       "      <td>139430000.0</td>\n",
       "      <td>4.95</td>\n",
       "      <td>1.11</td>\n",
       "      <td>17.1200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.95</td>\n",
       "      <td>38.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.483110e+08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>26.98</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.59</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.77</td>\n",
       "      <td>8630000.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>15.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SRCE</td>\n",
       "      <td>12</td>\n",
       "      <td>3.350</td>\n",
       "      <td>11.61</td>\n",
       "      <td>13.25</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.43</td>\n",
       "      <td>240</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>130670000.0</td>\n",
       "      <td>291490000.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.23</td>\n",
       "      <td>117890000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1st Source Corporation</td>\n",
       "      <td>348340000.0</td>\n",
       "      <td>4.52</td>\n",
       "      <td>1.34</td>\n",
       "      <td>44.0200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.52</td>\n",
       "      <td>39.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.133000e+09</td>\n",
       "      <td>4.62</td>\n",
       "      <td>29.01</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.04</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2.48</td>\n",
       "      <td>25960000.0</td>\n",
       "      <td>1.08</td>\n",
       "      <td>4</td>\n",
       "      <td>31.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Sector  Diluted EPS  Revenue Per Share Trailing P/E  \\\n",
       "0    PIH      12       -1.185               9.73            0   \n",
       "1   TURN      12       -0.091               0.01            0   \n",
       "2   FLWS      10        0.520              19.41        28.31   \n",
       "3   FCCY      12        1.620               6.13        10.77   \n",
       "4   SRCE      12        3.350              11.61        13.25   \n",
       "\n",
       "   Forward Annual Dividend Rate  Price/Book  Industry  Revenue  \\\n",
       "0                          0.00        0.69       327     0.76   \n",
       "1                          0.00        0.75       156   282.44   \n",
       "2                          0.00        2.76       303     0.72   \n",
       "3                          0.30        1.11       379     4.95   \n",
       "4                          1.08        1.43       240     4.52   \n",
       "\n",
       "   Enterprise Value/EBITDA  Return on Equity  EBITDA  Operating Cash Flow  \\\n",
       "0                   118.12              0.97  118.12            8630000.0   \n",
       "1                   -24.40             -3.19  -24.40           -5850000.0   \n",
       "2                    11.96             10.57   11.96           78100000.0   \n",
       "3                     0.00             11.03    0.00           14330000.0   \n",
       "4                     0.00             11.25    0.00          130670000.0   \n",
       "\n",
       "   Gross Profit  Quarterly Earnings Growth  PEG Ratio   Total Cash  \\\n",
       "0    15490000.0                        0.0       0.00    2310000.0   \n",
       "1           0.0                      -39.9       0.00    5870000.0   \n",
       "2   526120000.0                        0.0       1.34  172920000.0   \n",
       "3    50220000.0                       80.1       1.32   30110000.0   \n",
       "4   291490000.0                        6.5       1.23  117890000.0   \n",
       "\n",
       "   Total Debt/Equity                                    Name   Total Debt  \\\n",
       "0                0.0  1347 Property Insurance Holdings, Inc.          0.0   \n",
       "1                0.0                180 Degree Capital Corp.          0.0   \n",
       "2               28.3                 1-800 FLOWERS.COM, Inc.   96970000.0   \n",
       "3                0.0           1st Constitution Bancorp (NJ)  139430000.0   \n",
       "4                0.0                  1st Source Corporation  348340000.0   \n",
       "\n",
       "   Enterprise Value  Return on Assets    Price  EPS Beat Ratio  Current Ratio  \\\n",
       "0              0.76              0.10   4.8348             0.0           1.35   \n",
       "1            282.44             -1.64   2.1294             0.0           1.45   \n",
       "2              0.72              4.79  15.4100             0.0           2.38   \n",
       "3              4.95              1.11  17.1200             0.0           0.00   \n",
       "4              4.52              1.34  44.0200             0.0           0.00   \n",
       "\n",
       "   Enterprise Value/Revenue  Operating Margin  IPO Year    Market Cap  \\\n",
       "0                      0.76              0.42    2014.0  2.922200e+07   \n",
       "1                    282.44              0.00       0.0  6.654100e+07   \n",
       "2                      0.72              3.61    1999.0  9.542680e+08   \n",
       "3                      4.95             38.79       0.0  1.483110e+08   \n",
       "4                      4.52             39.49       0.0  1.133000e+09   \n",
       "\n",
       "   Total Cash Per Share  Profit Margin  Price/Sales  Levered Free Cash Flow  \\\n",
       "0                  0.38          -9.79         0.50             -80710000.0   \n",
       "1                  0.19           0.00       314.30               2120000.0   \n",
       "2                  2.69           2.78         0.76              34370000.0   \n",
       "3                  3.48          26.98         2.84                     0.0   \n",
       "4                  4.62          29.01         3.78                     0.0   \n",
       "\n",
       "   Forward Annual Dividend Yield  5 Year Average Dividend Yield  Beta   \\\n",
       "0                           0.00                           0.00    0.0   \n",
       "1                           0.00                           0.00    0.0   \n",
       "2                           0.00                           0.00    0.0   \n",
       "3                           1.77                           0.00    0.0   \n",
       "4                           2.48                           1.95    0.0   \n",
       "\n",
       "   Net Income  Payout Ratio  Beta  Dividend Yield  Shares Outstanding  \\\n",
       "0         0.0          0.00  0.37            0.00           6010000.0   \n",
       "1         0.0          0.00  0.69            0.00          31120000.0   \n",
       "2         0.0          0.00  1.24            0.00          35770000.0   \n",
       "3         0.0         17.59  0.13            1.77           8630000.0   \n",
       "4         0.0         31.04  1.36            2.48          25960000.0   \n",
       "\n",
       "   Dividend Rate  index  Book Value Per Share  Quarterly Revenue Growth  \\\n",
       "0           0.00      0                  7.00                       0.0   \n",
       "1           0.00      1                  2.82                       0.0   \n",
       "2           0.00      2                  5.33                       0.0   \n",
       "3           0.30      3                 15.62                       0.0   \n",
       "4           1.08      4                 31.12                       0.0   \n",
       "\n",
       "   Forward P/E  \n",
       "0         0.00  \n",
       "1         0.00  \n",
       "2        21.65  \n",
       "3         9.78  \n",
       "4        12.09  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_col_attributes(col_name):\n",
    "    replacements = {\n",
    "                        '(TTM)' : '',\n",
    "                        '(ttm)' : '',\n",
    "                        '(YOY)' : '',\n",
    "                        ' (intraday)' : '',\n",
    "                        ' (5 yr expected)' : '',\n",
    "                        '(5yr Expected)': '',\n",
    "                        '(3Y Monthly)' : '',\n",
    "                        ' (3Y Monthly)' : '',\n",
    "                        ' Avi to Common' : '',\n",
    "                        'Trailing Annual ' : ''\n",
    "                   }\n",
    "    for code, replacement in replacements.items():\n",
    "        col_name = col_name.replace(code, replacement)\n",
    "    return col_name\n",
    "\n",
    "\n",
    "# Get the unique column values in the dataframe so we can combine data\n",
    "unique_attributes = set([parse_col_attributes(col) for col in financial_data.columns])\n",
    "    \n",
    "# Iterate through attributes and fill master_data\n",
    "master_data = pd.DataFrame()\n",
    "for attribute in tqdm(unique_attributes):\n",
    "    supporting_attributes = [x for x in financial_data.columns if attribute in x]\n",
    "    master_data[attribute] = financial_data[supporting_attributes[0]]\n",
    "    # Combine columns with same attribute using the non zero value\n",
    "    for i in range(1, len(supporting_attributes)):\n",
    "        master_data[attribute] = master_data[attribute].combine(financial_data[supporting_attributes[i]], lambda x, y: x if (y == 0 or float('nan')) else y)\n",
    "    \n",
    "master_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data_truncated = master_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of training data: Index(['Sector', 'Diluted EPS', 'Revenue Per Share', 'Trailing P/E',\n",
      "       'Price/Book', 'Industry', 'Revenue', 'Return on Equity', 'EBITDA',\n",
      "       'Operating Cash Flow', 'Gross Profit', 'Quarterly Earnings Growth',\n",
      "       'PEG Ratio', 'Total Cash', 'Total Debt/Equity', 'Total Debt',\n",
      "       'Enterprise Value', 'Return on Assets', 'Current Ratio',\n",
      "       'Operating Margin', 'Market Cap', 'Total Cash Per Share',\n",
      "       'Profit Margin', 'Price/Sales', 'Levered Free Cash Flow', 'Net Income',\n",
      "       'Beta', 'Dividend Yield', 'Shares Outstanding', 'Dividend Rate',\n",
      "       'Book Value Per Share', 'Quarterly Revenue Growth', 'Forward P/E'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\preprocessing\\data.py:172: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "ename": "IndexingError",
     "evalue": "(slice(None, None, None), slice(None, None, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_setitem_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1085\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_for_reindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1086\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1087\u001b[0m             \u001b[0mkeyarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer_for\u001b[1;34m(self, target, **kwargs)\u001b[0m\n\u001b[0;32m   4816\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4817\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4818\u001b[0m         \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   2979\u001b[0m             return this.get_indexer(\n\u001b[1;32m-> 2980\u001b[1;33m                 \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3004\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.lookup\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'slice'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-99e196241ee3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Standardize the data to mean 0 and std 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Hyperparameter tune settings for XGBoost model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_setitem_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"cannot do\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexingError\u001b[0m: (slice(None, None, None), slice(None, None, None))"
     ]
    }
   ],
   "source": [
    "# Columns to ignore when training\n",
    "ignore_columns = ['Price', 'Ticker', 'Name', 'IPO Year', 'Payout Ratio', 'Enterprise Value/EBITDA', 'Enterprise Value/Revenue',\n",
    "                 'Trailing Annual Dividend Rate', 'Forward Annual Dividend Rate', 'Forward Annual Dividend Yield',\n",
    "                 '5 Year Average Dividend Yield', 'EPS Beat Ratio', 'Beta ', 'index']\n",
    "# Keep track of categoricals so we can convert them to numeric\n",
    "categoricals = ['Sector', 'Industry']\n",
    "\n",
    "# Store the data we want to learn from in X\n",
    "X = master_data_truncated[[c for c in master_data_truncated.columns if c not in ignore_columns]]\n",
    "for c in X.columns:\n",
    "    X[c] = pd.to_numeric(X[c], errors='coerce')\n",
    "#X = pd.get_dummies(X, columns=categoricals)\n",
    "#Y = Y.head(int(len(master_data) / 10))\n",
    "\n",
    "# Get training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=123)\n",
    "print('Columns of training data:', X_train.columns)\n",
    "\n",
    "X_train=(X_train-X_train.min())/(X_train.max()-X_train.min())\n",
    "y_train=(y_train-y_train.min())/(y_train.max()-y_train.min())\n",
    "# Standardize the data to mean 0 and std 1 \n",
    "X_train.loc[:,:] = preprocessing.scale(X_train)\n",
    "y_train.loc[:,:] = preprocessing.scale(y_train)\n",
    "\n",
    "# Hyperparameter tune settings for XGBoost model\n",
    "param_test = {\n",
    "    'max_depth':[3],\n",
    "    'min_child_weight':[4],\n",
    "    'learning_rate':[.25],\n",
    "    'gamma':[0],\n",
    "    'reg_alpha':[ 0.1]#, .12, .14]\n",
    "}\n",
    "\n",
    "# Define XGB model object\n",
    "xgbr = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Define grid search object and feed in the model we created\n",
    "gsearch = GridSearchCV(estimator=xgbr, param_grid=param_test,n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "# Fit perform the grid search\n",
    "gsearch.fit(X_train, y_train)\n",
    "print(\"Test Score: \" + str(gsearch.best_estimator_.score(X_test, y_test)))\n",
    "model = gsearch.best_estimator_\n",
    "preds = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "model.save_model('xgb_main.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gross Profit', 'Total Debt', 'Book Value Per Share', 'index',\n",
       "       'Dividend Yield', 'Shares Outstanding', 'Price/Book', 'PEG Ratio',\n",
       "       'Forward P/E', 'Quarterly Earnings Growth', 'Revenue Per Share',\n",
       "       'Total Debt/Equity', 'Beta ', 'Current Ratio', 'Market Cap',\n",
       "       'Return on Equity', 'Levered Free Cash Flow',\n",
       "       'Quarterly Revenue Growth', 'Operating Margin', 'Net Income',\n",
       "       'Industry', 'Return on Assets', 'Dividend Rate', 'Price/Sales',\n",
       "       'EBITDA', 'Trailing P/E', 'Revenue', 'Beta', 'Diluted EPS',\n",
       "       'Total Cash Per Share', 'Sector', 'Enterprise Value', 'Profit Margin',\n",
       "       'Total Cash', 'Operating Cash Flow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index is not in self.metadata\n",
      "Beta  is not in self.metadata\n",
      "Dividend Rate is not in self.metadata\n",
      "    Gross Profit  Total Debt  Book Value Per Share  Dividend Yield  \\\n",
      "0  2336461000000         NaN          1.973676e-08             0.6   \n",
      "\n",
      "   Shares Outstanding  Price/Book  PEG Ratio  Forward P/E  \\\n",
      "0          1220160000    3.174985      -1.32    16.585682   \n",
      "\n",
      "   Quarterly Earnings Growth  Revenue Per Share  ...  Trailing P/E  Revenue  \\\n",
      "0                      -85.6                NaN  ...     16.073154      NaN   \n",
      "\n",
      "       Beta  Diluted EPS  Total Cash Per Share  Sector  Enterprise Value  \\\n",
      "0  1.151744        4.757                   NaN     NaN       93293428736   \n",
      "\n",
      "   Profit Margin  Total Cash  Operating Cash Flow  \n",
      "0          7.048         NaN                  NaN  \n",
      "\n",
      "[1 rows x 32 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([209.86879], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from company import *\n",
    "company = Company(\"SNE\")\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "model.load_model('xgb_main.model')\n",
    "company.predict_price_using_xgb(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_init(x):\n",
    "    x = x.weight.data\n",
    "    sc = 2/(x.size(1)+1)\n",
    "    x.uniform_(-sc,sc)\n",
    "    \n",
    "def inv_y(y): \n",
    "    return np.exp(y)\n",
    "    \n",
    "def rmse(targ, y_pred):\n",
    "    #print(inv_y(y_pred), inv_y(targ))\n",
    "    #return np.sqrt(mean_squared_error(inv_y(y_pred), inv_y(targ))) #.detach().numpy()\n",
    "    return np.sqrt(mean_squared_error(y_pred, targ))\n",
    "\n",
    "\n",
    "class MixedInputModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops, y_range, use_bn=True):\n",
    "        super().__init__()\n",
    "        for i,(c,s) in enumerate(emb_szs): assert c > 1, \"cardinality must be >=2, got emb_szs[{i}]: ({c},{s})\"\n",
    "        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n",
    "        for emb in self.embs: emb_init(emb)\n",
    "        n_emb = sum(e.embedding_dim for e in self.embs)\n",
    "        self.n_emb, self.n_cont=n_emb, n_cont\n",
    "        \n",
    "        szs = [n_emb+n_cont] + szs\n",
    "        self.lins = nn.ModuleList([nn.Linear(szs[i], szs[i+1]) for i in range(len(szs)-1)])\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(sz) for sz in szs[1:]])\n",
    "        for o in self.lins: nn.init.kaiming_normal_(o.weight.data)\n",
    "        self.outp = nn.Linear(szs[-1], out_sz)\n",
    "        nn.init.kaiming_normal_(self.outp.weight.data)\n",
    "\n",
    "        self.emb_drop = nn.Dropout(emb_drop)\n",
    "        self.drops = nn.ModuleList([nn.Dropout(drop) for drop in drops])\n",
    "        self.bn = nn.BatchNorm1d(n_cont)\n",
    "        self.use_bn,self.y_range = use_bn,y_range\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]\n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.emb_drop(x)\n",
    "        if self.n_cont != 0:\n",
    "            x2 = self.bn(x_cont)\n",
    "            x = torch.cat([x, x2], 1) if self.n_emb != 0 else x2\n",
    "        for l,d,b in zip(self.lins, self.drops, self.bns):\n",
    "            x = F.relu(l(x))\n",
    "            if self.use_bn: x = b(x)\n",
    "            x = d(x)\n",
    "        x = self.outp(x)\n",
    "        if self.y_range:\n",
    "            x = torch.sigmoid(x)\n",
    "            x = x*(self.y_range[1] - self.y_range[0])\n",
    "            x = x+self.y_range[0]\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tqdm\\std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "y_range = (0, y_train.max()*1.2)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using: \" + str(device))\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "tqdm.pandas(desc='Progress')\n",
    "\n",
    "cat_sz = [(c, financial_data[c].max()+1) for c in categorical]\n",
    "\n",
    "\n",
    "emb_szs = [(c, min(50, (c+1)//2)) for _,c in cat_sz]\n",
    "\n",
    "\n",
    "net = MixedInputModel(emb_szs=emb_szs,\n",
    "    n_cont=len(financial_data.columns)-len(categorical) - 4, \n",
    "                    emb_drop=0.04,\n",
    "                    out_sz=1, \n",
    "                    szs=[1000,500,250], \n",
    "                    drops=[0.001,0.01,0.01], \n",
    "                    y_range=y_range).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_dl, val_dl, loss_fn, opt, scheduler, epochs=3):\n",
    "    num_batch = len(train_dl)\n",
    "    for epoch in tnrange(epochs):      \n",
    "        y_true_train = list()\n",
    "        y_pred_train = list()\n",
    "        total_loss_train = 0          \n",
    "        t = tqdm(iter(train_dl), leave=False, total=num_batch)\n",
    "        for cat, cont, y in t:\n",
    "            cat = cat.cuda()\n",
    "            cont = cont.cuda()\n",
    "            y = y.cuda()\n",
    "            \n",
    "            t.set_description('Epoch {epoch}')\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            pred = model(cat, cont)\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            lr[epoch].append(opt.param_groups[0]['lr'])\n",
    "            tloss[epoch].append(loss.item())\n",
    "            opt.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            t.set_postfix(loss=loss.item())\n",
    "            \n",
    "            y_true_train += list(y.cpu().data.numpy())\n",
    "            y_pred_train += list(pred.cpu().data.numpy())\n",
    "            total_loss_train += loss.item()\n",
    "        train_acc = rmse(y_true_train, y_pred_train)\n",
    "        train_loss = total_loss_train/len(train_dl)\n",
    "        \n",
    "        if val_dl:\n",
    "            y_true_val = list()\n",
    "            y_pred_val = list()\n",
    "            total_loss_val = 0\n",
    "            for cat, cont, y in tqdm(val_dl, leave=False):\n",
    "                cat = cat.cuda()\n",
    "                cont = cont.cuda()\n",
    "                y = y.cuda()\n",
    "                pred = model(cat, cont)\n",
    "                loss = loss_fn(pred, y)\n",
    "                \n",
    "                y_true_val += list(y.cpu().data.numpy())\n",
    "                y_pred_val += list(pred.cpu().data.numpy())\n",
    "                total_loss_val += loss.item()\n",
    "                vloss[epoch].append(loss.item())\n",
    "            valacc = rmse(y_true_val, y_pred_val)\n",
    "            valloss = total_loss_val/len(valdl)\n",
    "            print(f'Epoch {epoch}: train_loss: {train_loss:.4f} train_rmse: {train_acc:.4f} | val_loss: {valloss:.4f} val_rmse: {valacc:.4f}')\n",
    "        else:\n",
    "            print(f'Epoch {epoch}: train_loss: {train_loss:.4f} train_rmse: {train_acc:.4f}')\n",
    "    \n",
    "    return lr, tloss, vloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3ff2eb8ec147c4be2261c4878c48b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_loss: 143187.8867 train_rmse: 380.3524 | val_loss: 61331.3984 val_rmse: 247.9860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 42662.5648 train_rmse: 206.4694 | val_loss: 23839.9443 val_rmse: 154.2657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss: 23486.3899 train_rmse: 149.1934 | val_loss: 19826.0840 val_rmse: 140.9616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss: 14543.7830 train_rmse: 120.0164 | val_loss: 11771.1118 val_rmse: 108.3218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss: 14461.9428 train_rmse: 116.8064 | val_loss: 15204.5037 val_rmse: 123.2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss: 12083.2050 train_rmse: 109.4976 | val_loss: 9274.1831 val_rmse: 96.3269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss: 9508.1729 train_rmse: 97.7069 | val_loss: 7797.2927 val_rmse: 88.3143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss: 7159.7936 train_rmse: 85.4145 | val_loss: 4835.0792 val_rmse: 69.6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss: 2676.9693 train_rmse: 52.2332 | val_loss: 2998.1369 val_rmse: 54.8395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss: 1735.1614 train_rmse: 41.5855 | val_loss: 2740.0311 val_rmse: 52.4122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss: 1583.4377 train_rmse: 39.3441 | val_loss: 1819.1826 val_rmse: 42.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_loss: 1415.2400 train_rmse: 37.3986 | val_loss: 2401.2045 val_rmse: 48.9974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_loss: 2487.3224 train_rmse: 48.3532 | val_loss: 3380.5993 val_rmse: 58.3112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_loss: 1985.2265 train_rmse: 44.9665 | val_loss: 2437.4544 val_rmse: 49.4118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_loss: 2075.7595 train_rmse: 45.7832 | val_loss: 2451.0959 val_rmse: 49.5564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_loss: 1646.2713 train_rmse: 40.7855 | val_loss: 1711.1389 val_rmse: 41.3387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train_loss: 1342.1066 train_rmse: 36.3244 | val_loss: 2706.0354 val_rmse: 51.7468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train_loss: 1232.7868 train_rmse: 34.8426 | val_loss: 2697.6000 val_rmse: 52.0755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: train_loss: 1523.0074 train_rmse: 38.8335 | val_loss: 2263.8178 val_rmse: 47.4521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: train_loss: 1195.1422 train_rmse: 34.6402 | val_loss: 1810.0902 val_rmse: 42.5341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: train_loss: 1056.3391 train_rmse: 32.4586 | val_loss: 1874.5223 val_rmse: 43.2818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: train_loss: 922.3789 train_rmse: 30.5236 | val_loss: 1887.0161 val_rmse: 43.4477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: train_loss: 954.3424 train_rmse: 30.7996 | val_loss: 1723.1543 val_rmse: 41.3798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: train_loss: 950.9985 train_rmse: 30.2787 | val_loss: 1593.2052 val_rmse: 39.8929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: train_loss: 974.9548 train_rmse: 31.5040 | val_loss: 1877.6741 val_rmse: 43.3968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: train_loss: 1002.8527 train_rmse: 30.8385 | val_loss: 1522.5733 val_rmse: 38.9560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: train_loss: 822.8628 train_rmse: 28.9190 | val_loss: 1768.8363 val_rmse: 42.1615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: train_loss: 930.4333 train_rmse: 29.7077 | val_loss: 1553.0998 val_rmse: 39.3339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: train_loss: 774.7160 train_rmse: 27.9390 | val_loss: 1274.6051 val_rmse: 35.7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: train_loss: 779.9548 train_rmse: 28.0416 | val_loss: 1566.4821 val_rmse: 39.6351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: train_loss: 834.5501 train_rmse: 28.2992 | val_loss: 1703.0353 val_rmse: 41.2271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: train_loss: 717.7432 train_rmse: 27.0968 | val_loss: 1937.1578 val_rmse: 44.0460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: train_loss: 856.3053 train_rmse: 28.8783 | val_loss: 1429.7929 val_rmse: 37.8479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: train_loss: 744.3978 train_rmse: 26.9310 | val_loss: 1624.4129 val_rmse: 40.3265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: train_loss: 739.6438 train_rmse: 27.0740 | val_loss: 1518.7814 val_rmse: 39.0461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: train_loss: 977.4771 train_rmse: 29.8315 | val_loss: 1635.8975 val_rmse: 40.3657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: train_loss: 819.2220 train_rmse: 28.8090 | val_loss: 1501.9390 val_rmse: 38.8157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: train_loss: 804.0188 train_rmse: 28.1621 | val_loss: 2632.2092 val_rmse: 51.0499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: train_loss: 850.7130 train_rmse: 29.4151 | val_loss: 1583.0110 val_rmse: 39.6255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: train_loss: 694.2683 train_rmse: 26.3039 | val_loss: 1248.8002 val_rmse: 35.3439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: train_loss: 790.5785 train_rmse: 27.3483 | val_loss: 1745.4403 val_rmse: 41.7439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: train_loss: 661.1110 train_rmse: 25.9517 | val_loss: 1591.1133 val_rmse: 39.9033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: train_loss: 701.0955 train_rmse: 26.8022 | val_loss: 2888.9241 val_rmse: 53.7998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: train_loss: 2264.5892 train_rmse: 48.1293 | val_loss: 1578.8861 val_rmse: 39.6327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: train_loss: 984.7735 train_rmse: 31.5662 | val_loss: 1935.8121 val_rmse: 44.0901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: train_loss: 942.4435 train_rmse: 29.5984 | val_loss: 1576.4538 val_rmse: 39.7493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: train_loss: 781.2460 train_rmse: 28.2044 | val_loss: 1591.6786 val_rmse: 40.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: train_loss: 717.0555 train_rmse: 26.8132 | val_loss: 1485.5380 val_rmse: 38.5979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: train_loss: 762.0789 train_rmse: 27.9332 | val_loss: 1337.8738 val_rmse: 36.6281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: train_loss: 892.1409 train_rmse: 30.2684 | val_loss: 1167.5138 val_rmse: 34.1897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(net.parameters(), 1e-2)\n",
    "lr_cosine = lr_scheduler.CosineAnnealingLR(opt, 1000)\n",
    " \n",
    "lr = defaultdict(list)\n",
    "tloss = defaultdict(list)\n",
    "vloss = defaultdict(list)\n",
    " \n",
    "lr, tloss, vloss = fit(model=net, train_dl=traindl, val_dl=valdl, loss_fn=F.mse_loss, opt=opt, scheduler=lr_cosine, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = [np.mean(tloss[el]) for el in tloss]\n",
    "v = [np.mean(vloss[el]) for el in vloss]\n",
    "p = pd.DataFrame({'Train Loss': t, 'Validation Loss': v, 'Epochs': range(50)})\n",
    "\n",
    "_ = p.plot(x='Epochs', y=['Train Loss', 'Validation Loss'], \n",
    "           title='Train and Validation Loss over Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [x for x in feature_cols if x not in ['Industry', 'Sector']]\n",
    "#m.eval()\n",
    "\n",
    "X = financial_data[feature_cols]\n",
    "Y = financial_data['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=123)\n",
    "    \n",
    "# Covert to dataloaders\n",
    "traindl = apply_dl(X_train, y_train, categorical)\n",
    "valdl = apply_dl(X_test, y_test, categorical)\n",
    "\n",
    "one, two, three,  four,  five = valdl\n",
    "\n",
    "y_pred = m(one[0].cuda(), one[1].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "state": {
    "633ee280727a4e038b3607a73dbd767e": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "b9a531e5be584c349f802bb340fde436": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
